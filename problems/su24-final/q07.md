# BEGIN PROB

You are analyzing the data in `stages` to see which countries winners come from.

You categorize the countries into four groups: France, Italy, Belgium, and Other. After performing some analysis, you find that the observed distribution of countries of origin for Tour de France stage winners is $[0.3, 0.2, 0.1, 0.4]$; i.e. 30% of stage winners are French, 20% Italian, etc. Based on census information, the expected population distribution is $[0.07, 0.06, 0.01, 0.86]$; that is, France's total population is 7% of the sum of the populations of all countries participating in the Tour, Italy's is 6%, etc.

You conduct a hypothesis test with the following hypotheses:

-   **Null Hypothesis**: The distribution of countries of origin for Tour de France stage winners is equivalent to the distribution of the populations of the countries participating in the Tour de France. Any observed difference is due to chance.
-   **Alternative Hypothesis**: The distribution of countries of origin for Tour de France stage winners is different from the distribution of the populations of the countries participating in the Tour de France.

# BEGIN SUBPROB

Which of the following test statistics are appropriate for this hypothesis test? Select all that apply.

[ ] The absolute difference between the expected proportion of French stage winners and the observed proportion of French stage winners.
[ ] The sum of the differences between the expected population distribution and the observed distribution of stage winners.
[ ] The absolute difference between the number of French stage winners and the number of Italian stage winners.
[ ] The sum of the absolute differences between the expected population distribution and the observed distribution of stage winners.

# BEGIN SOLUTION
**Solution:** Option 1 and Option 4

- Option 1 is correct. The absolute difference between the expected proportion of French stage winners and the observed proportion of French stage winners gives the magnitude of the difference in distributions making this a valid test statistic. 
- Option 2 is incorrect. The sum of the differences between the expected population distribution and the observed distribution of stage winners is not a valid test statistic since it indicates a direction to the difference when we only want to know whether these distributions are different. 
- Option 3 is incorrect. The absolute difference between the number of French stage winners and the number of Italian stage winners is not a valid test statistic since the numbers in each population can be different and thus the difference in numbers is not a fair comparison. 
- Option 4 is correct. The sum of the absolute differences between the expected population distribution and the observed distribution of stage winners gives magnitude but does not indicate direction making this a valid test statistic. 


# END SOLUTION

# END SUBPROB

**For the rest of this question, assume that we will be using the Total Variation Distance as our test statistic.**

# BEGIN SUBPROB

Complete the implementation of the `simulate` and `calculate_test_stat` functions so that the code below successfully simulates 10,000 test statistics.

```py

expected_dist = [0.07, 0.06, 0.01, 0.86]
observed_dist = [0.3, 0.2, 0.1, 0.4]

def simulate(__(i)__):
    simulated_winners = np.random.__(ii)__(100, __(iii)__)
    return simulated_winners / 100

def calculate_test_stat(__(iv)__, __(v)__):
    return __(vi)__


observed_stat = calculate_test_stat(observed_dist, expected_dist)
simulated_stats = np.array([])
for i in np.arange(10000):
    simulated_dist = simulate(expected_dist)
    simulated_stat = calculate_test_stat(simulated_dist, expected_dist)
    simulated_stats = np.append(simulated_stats, simulated_stat)
```

# BEGIN SOLUTION

**Solution:**

- \(i\): `expected_dist`
- \(ii\): `multinomial`
- \(iii\): `expected_dist`
- \(iv\): `simulated_dist`
- \(v\): `expected_dist` (or swapped with above)
- \(vi\): `np.abs(simulated dist - expected dist).sum() / 2`

When performing a simulation, we simulated based on the expectation. Thus, the argument for the simulate function (i) should be the `expected_dist` array. In this function, we simulate winners based on the expected distribution. So, we want to use `np.random.multinomial` in (ii) which will take in the number of experiments and expected distribution, ie (iii), which is an array of the probabilities for each of the outcomes.

We are using the total variation distance as the test statistic. The Total Variation Distance (TVD) of two categorical distributions is the sum of the absolute differences of their proportions, all divided by 2. Thus, the arguments of the `calculate_test_stat` function should be the `simulated_distribution` in (iv) and the `expected_distribution` in (v) (or swapped). In this function, we need to return the TVD which can be calculated as follows: `np.abs(simulated dist - expected dist).sum() / 2` in (vi).


# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

Fill in the blank in the following code so that `p_value` evaluates to
the correct p-value for this hypothesis test:

```py
    p_value = np.mean(simulated_stats ___ observed_statistic)
```

( ) \>
( ) >=
( ) <
( ) <=
( ) =

# BEGIN SOLUTION
**Solution:** $>=$

Recall the p-value is the probability of seeing a result equal to or more extreme than the observed value under the null hypothesis. Since the TVD is our test statistic where greater values indicate a result more extreme that means we want to use $>=$ in the blank to check whether the simulated statistic is equal to or more extreme than the observed statistic. 

# END SOLUTION

# END SUBPROB

# END PROB