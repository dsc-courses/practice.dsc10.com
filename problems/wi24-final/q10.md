# BEGIN PROB

We want to use the sample of data in `olympians` to
estimate the mean age of Olympic beach volleyball players.

# BEGIN SUBPROB

Which of the following distributions must be normally distributed in
order to use the Central Limit Theorem to estimate this parameter?

( ) The age distribution of all Olympic athletes.
( ) The age distribution of Olympic beach volleyball players.
( ) The age distribution of Olympic beach volleyball in our sample.
( ) None of the above.

# BEGIN SOLUTION
**Answer:** None of the Above

The central limit theorem states that the distribution of possible **sample means** and sample sums is approximately normal, no matter the distribution of the population. Options A, B, and C are not probability distributions of the sum or mean of a large random sample draw with replacement.

<average>72</average>

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

(10 pts) Next we want to use bootstrapping to estimate this parameter.
Which of the following code implementations correctly generates an array
called `sample_means` containing $10,000$ bootstrapped sample means?

Way 1:
```py
    sample_means = np.array([])
    for i in np.arange(10000):
        bv = olympians[olympians.get("Sport") == "Beach Volleyball"]
        one_mean = (bv.sample(bv.shape[0], replace=True)
                      .get("Age").mean())
        sample_means = np.append(sample_means, one_mean)
```

Way 2:
```py
    sample_means = np.array([])
    for i in np.arange(10000):
        bv = olympians[olympians.get("Sport") == "Beach Volleyball"]
        one_mean = (olympians.sample(olympians.shape[0], replace=True)
                             .get("Age").mean())
        sample_means = np.append(sample_means, one_mean)
```
Way 3:
```py
    sample_means = np.array([])
    for i in np.arange(10000):
        resample = olympians.sample(olympians.shape[0], replace=True)
        bv = resample[resample.get("Sport") == "Beach Volleyball"]
        one_mean = bv.get("Age").mean()
        sample_means = np.append(sample_means, one_mean)
```
Way 4:
```py
    sample_means = np.array([])
    bv = olympians[olympians.get("Sport") == "Beach Volleyball"]
    for i in np.arange(10000):
        one_mean = (bv.sample(bv.shape[0], replace=True)
                      .get("Age").mean())
        sample_means = np.append(sample_means, one_mean)
```
Way 5:
```py
    sample_means = np.array([])
    bv = olympians[olympians.get("Sport") == "Beach Volleyball"]
    one_mean = (bv.sample(bv.shape[0], replace=True)
                  .get("Age").mean())
    for i in np.arange(10000):
        sample_means = np.append(sample_means, one_mean)
```

[ ] Way 1
[ ] Way 2
[ ] Way 3
[ ] Way 4
[ ] Way 5

# BEGIN SOLUTION
**Answer:** Way 1 and Way 4  

- Way 1 first creates a DataFrame `bv`, which is a subset DataFrame of `olympians` but filtered to only have `"Beach Volleyball"`. It then samples from `bv` with replacement, and counts the mean of that sample and stores it in the variable `one_sample`. It does this 10,000 times (due to the for loop), each time creating a dataframe `bv`, sampling from it, calculating a mean, and then appending `one_sample` to the array `sample_means`. This is a correct way to bootstrap.
- Way 2 is incorrect because it calculates one_mean using a sample from the entire `olympians` DataFrame, instead of the bv DataFrame with only the `"Beach Volleyball"` players. This will result in a sample of players of any sport, and the mean of those ages will be calculated.
- Way 3 is incorrect because it queries for rows where the data in the `"Sport"` column equals `"Beach Volleyball"` after sampling from the DataFrame instead of before. This would lead to a mean that is not representative of a sample of volleyball players' ages because we are sampling from all the rows with all different sports, most likely resulting in a smaller sample size of volleyball players. There would also be an inconsistent number of `"Beach Volleyball"` players in each sample.
- Way 4 is essentially the same as Way 1, except it creates the DataFrame `bv` before the for loop. The DataFrame `bv` will always be the same, so it doesn't really matter if we make `bv` before or after the for loop. 
- Way 5 is incorrect because the `one_mean` is calculated only once, but is appended to the `sample_means` array 10,000 times.  As a result, the same mean is being appended, instead of a different mean being calculated and appended each iteration.


<average>88</average>

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

For most of the answer choices in part (b), we do not have enough
information to predict how the standard deviation of `sample_means`
would come out. There is one answer choice, however, where we do have
enough information to compute the standard deviation of `sample_means`.
Which answer choice is this, and what is the standard deviation of
`sample_means` for this answer choice?

( ) Way 1
( ) Way 2
( ) Way 3
( ) Way 4
( ) Way 5

# BEGIN SOLUTION
**Answer:** Way 5

Way 5 results in a sample_means array with the same mean appended 10,000 times. As a result the standard deviation would be 0 because the entire array would be the same value repeated.

<average>57</average>

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

There are **68 rows** of `olympians` corresponding to beach volleyball
players. Assume that in part (b), we correctly generated an array called
`sample_means` containing 10,000 bootstrapped sample mean ages based on
this original sample of 68 ages. The standard deviation of the original
sample of 68 ages is approximately how many times larger than the
standard deviation of `sample_means`? Give your answer to the nearest
integer.


# BEGIN SOLUTION
**Answer:** 8

 Recall SD of sample_means = $\frac{\text{Population SD}}{\sqrt{\text{sample size}}}$. The sample size equals 68. Based on this equation, the population SD is $\sqrt{68}$ times larger than the SD of distribution of possible sample means.  $\sqrt{68}$ rounded to the nearest integer is 8.

<average>46</average>

# END SOLUTION

# END SUBPROB

# END PROB