# BEGIN PROB

On Reddit, Keenan also read that 22% of all online transactions are
fraudulent. He decides to test the following hypotheses at the **0.16
significance level**:

-   **Null Hypothesis**: The proportion of online transactions that are
    fraudulent is **0.22**.

-   **Alternative Hypothesis**: The proportion of online transactions
    that are fraudulent is not **0.22**.

Keenan has access to a simple random sample of `txn` of size **500**. In
his sample, the proportion of transactions that are fraudulent is
**0.23**.

Below is an incomplete implementation of the function `reject_null`,
which creates a bootstrap-based confidence interval and returns **True**
if the conclusion of Keenan's test is to **reject** the null hypothesis,
and **False** if the conclusion is to **fail to reject** the null
hypothesis, all at the **0.16** significance level.
```py
    def reject_null():
        fraud_counts = np.array([])
        for i in np.arange(10000):
            fraud_count = np.random.multinomial(500, __(a)__)[0] 
            fraud_counts = np.append(fraud_counts, fraud_count)
            
        L = np.percentile(fraud_counts, __(b)__)
        R = np.percentile(fraud_counts, __(c)__)

        if __(d)__ < L or __(d)__ > R:
            # Return True if we REJECT the null.
            return True
        else:
            # Return False if we FAIL to reject the null.
            return False
```

Fill in the blanks so that `reject_null` works as intended.

*Hint: Your answer to (d) should be an integer greater than 50.*

# BEGIN SOLUTION
**Answer:** (a): `[0.23, 0.77]`, (b): `8`, (c): `92`, (d): `110`

(a): We know that the proportion of fraudulent transactions in the sample is 0.23 (and therefore the non-fraudulent proportion is 0.77), so we use these as the probabilities for `np.random.multinomial` in our bootstrapping simulation. The syntax for this function requires us to pass in the probabilities as a list, so the answer is `[0.23, 0.77]`.

<average>23</average>

(b): Since weâ€™re testing at the 0.16 significance level, we know that the proportion of data lying outside either of our endpoints is 0.16, or 0.8 on each side. So, the left endpoint is given by the 8th percentile, which means that the argument to `np.percentile` must be 8.

<average>67</average>


(c): Similar to part B, we know that 0.08 of the data must lie to the right of the right endpoint, so the argument to `np.percentile` here is $(1 - 0.08) \cdot 100 = 92$.

<average>67</average>

(d): To test our hypothesis, we must compare the left and right endpoints to the observed value. If the observed value is less than the left endpoint or greater than the right endpoint, we will reject the null hypothesis. Otherwise we fail to reject it. Since the left and right endpoints give the count of fraudulent transactions (not the proportion), we must convert our null hypothesis to similar terms. We can simply multiply the sample size by the proportion of fraudulent transactions to obtain the count that the null hypothesis would suggest given the sample size of 500, which gives us $500 * 0.22 = 110$.

<average>26</average>


# END SOLUTION

# END PROB