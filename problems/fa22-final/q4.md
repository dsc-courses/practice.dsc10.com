# BEGIN PROB

In `apps`, our sample of 1,000 credit card applications, applicants who were approved for the credit card have fewer dependents, on average, than applicants who were denied. The mean number of dependents for approved applicants is 0.98, versus 1.07 for denied applicants.

To test whether this difference is purely due to random chance, or whether the distributions of the number of dependents for approved and denied applicants are truly different in the population of all credit card applications, we decide to perform a permutation test.

Consider the incomplete code block below.

```py
def shuffle_status(df):
    shuffled_status = np.random.permutation(df.get("status"))
    return df.assign(status=shuffled_status).get(["status", "dependents"])

def test_stat(df):
    grouped = df.groupby("status").mean().get("dependents")
    approved = grouped.loc["approved"]
    denied = grouped.loc["denied"]
    return __(a)__

stats = np.array([])
for i in np.arange(10000):
    shuffled_apps = shuffle_status(apps)
    stat = test_stat(shuffled_apps)
    stats = np.append(stats, stat)

p_value = np.count_nonzero(__(b)__) / 10000
```

Below are six options for filling in blanks (a) and (b) in the code above.

(insert table)

The correct way to fill in the blanks depends on how we choose our null and alternative hypotheses. 


# BEGIN SUBPROB

Suppose we choose the following pair of hypotheses.
- **Null Hypothesis**: In the population, the number of dependents of accepted and denied applicants come from the same distribution.
- **Alternative Hypothesis**: In the population, the number of dependents of accepted applicants and denied applicants do not come from the same distribution.

Which of the six presented options could correctly fill in blanks (a) and (b) for this pair of hypotheses? Select all that apply.

[ ] Option 1
[ ] Option 2
[ ] Option 3
[ ] Option 4
[ ] Option 5
[ ] Option 6
[ ] None of the above.

# BEGIN SOLUTION

**Answer: **

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

    Now, suppose we choose the following pair of hypotheses.
    \begin{itemize}
        \item \textbf{Null Hypothesis}: In the population, the number of dependents of accepted and denied applicants come from the same distribution.
        \item \textbf{Alternative Hypothesis}: In the population, the number of dependents of accepted applicants is smaller on average than the number of dependents of denied applicants.
    \end{itemize}
    Which of the six presented options could correctly fill in blanks (a) and (b) for this pair of hypotheses? Select all that apply.

# BEGIN SOLUTION

**Answer: **

# END SOLUTION

# END SUBPROB

# BEGIN SUBPROB

# BEGIN SOLUTION

**Answer: **

# END SOLUTION

# END SUBPROB



# BEGIN SUBPROB

In our implementation of this permutation test, we followed the procedure outlined in lecture to draw new pairs of samples under the null hypothesis and compute test statistics --- that is, we randomly assigned each row to a group (approved or denied) by shuffling one of the columns in \texttt{apps}, then computed the test statistic on this random pair of samples.

Let's now explore an alternative solution to drawing pairs of samples under the null hypothesis and computing test statistics. Here’s the approach:

1. Shuffle, i.e. re-order, the rows of the DataFrame.
2. Use the values at the top of the resulting `"dependents"` column as the new "denied" sample, and the values at the at the bottom of the resulting `"dependents"` column as the new "approved" sample. Note that we don’t necessarily split the DataFrame exactly in half --- the sizes of these new samples depend on the number of "denied" and "approved" values in the original DataFrame!

Once we generate our pair of random samples in this way, we'll compute the test statistic on the random pair, as usual. Here, we'll use as our test statistic the difference between the mean number of dependents for denied and approved applicants, in the order **denied minus approved**.

**Fill in the blanks to complete the simulation below.**

*Hint:* `np.random.permutation` shouldn't appear anywhere in your code.

<center><img src='../assets/images/fa22-final/q4_code.png' width=60%></center>

# BEGIN SOLUTION
**Answer: ** The blanks should be filled in as follows:
- (a): `df.sample(df.shape[0])`
- (b): `df.take(np.arange(denied))`
- (c): `df.take(np.arange(denied+1, df.shape[0]))`

**For blank A**, the function wants to return a DataFrame with the same number of rows (the size of our sample), but wants 
these rows reordered. Note that the actual rows will be the same, so we want to sample without replacement (having only one
instance of each row in the old dataframe in the new dataframe). Baby Pandas provides the `.sample` method for this question.
`.sample` will sample dataframe rows where the first argument is the amount of samples, and the second (optional) argument is whether
or not we want to conduct sampling with replacement. As mentioned previously, we want the same number of rows which we can find using
`df.shape[0]` and do this sampling without replacement (the default behavior so we do not have to specify). 

**For blank B**, when we want to conduct a permutation test, the idea is to shuffle and combine the values
in two different groups. In this function the `denied` variable is the number of dependents values we need to take for our new sample of “denied” applicants.
To find the mean number of denied, we want to use `df.take(np.arange(denied))` to get the correct number
of denied applicants while also conducting shuffling.

**For blank C**, the logic falls similar to the logic mentioned above. Instead of denied applicants,
we are now looking at the approved applicants. To account for the number of approved applicants, we can use 
`df.take(np.arange(denied+1, df.shape[0]))` which accounts for the number of approved applicants (while also considering shuffling)
since it starts at `denied+1` to the end of the dataframe (which is found using `df.shape[0]`).


# END SOLUTION

# END SUBPROB

# END PROB
